{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2022/blob/master/12-architectures/TL_AE_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:19:29.305598Z",
     "iopub.status.busy": "2022-11-20T12:19:29.304997Z",
     "iopub.status.idle": "2022-11-20T12:19:31.757563Z",
     "shell.execute_reply": "2022-11-20T12:19:31.756141Z",
     "shell.execute_reply.started": "2022-11-20T12:19:29.305481Z"
    },
    "id": "z84mnv1t_425"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:19:31.760714Z",
     "iopub.status.busy": "2022-11-20T12:19:31.759296Z",
     "iopub.status.idle": "2022-11-20T12:19:31.766464Z",
     "shell.execute_reply": "2022-11-20T12:19:31.764974Z",
     "shell.execute_reply.started": "2022-11-20T12:19:31.760670Z"
    },
    "id": "fKajd0ZU_426"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f5af2eca-5b02-4d89-a36d-8ca330851ac3",
    "_uuid": "11db94b40434802ac10d5ed76e21d33b9ff6befe",
    "id": "FwTpmkJO_422"
   },
   "source": [
    "# Dog Breed Identification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IykQuyPyDlXs"
   },
   "source": [
    "Download the dataset from [Dog Breed Identification\n",
    " Competition](https://www.kaggle.com/competitions/dog-breed-identification/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43tf4uPHAa2O"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCEyHF13AMzx"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c dog-breed-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5gUVsn-A-6U"
   },
   "outputs": [],
   "source": [
    "!unzip dog-breed-identification.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIsz6XZv_429"
   },
   "source": [
    "Let's use 64 most frequent breeds to simplify the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:19:35.403850Z",
     "iopub.status.busy": "2022-11-20T12:19:35.403431Z",
     "iopub.status.idle": "2022-11-20T12:19:36.485851Z",
     "shell.execute_reply": "2022-11-20T12:19:36.484579Z",
     "shell.execute_reply.started": "2022-11-20T12:19:35.403818Z"
    },
    "id": "owX4xvVg_429"
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 64\n",
    "data_dir = '/content/data/'\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\n",
    "print(len(listdir(join(data_dir, 'train'))), len(labels))\n",
    "print(len(listdir(join(data_dir, 'test'))), len(sample_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:19:38.418926Z",
     "iopub.status.busy": "2022-11-20T12:19:38.418491Z",
     "iopub.status.idle": "2022-11-20T12:19:38.480493Z",
     "shell.execute_reply": "2022-11-20T12:19:38.479321Z",
     "shell.execute_reply.started": "2022-11-20T12:19:38.418889Z"
    },
    "id": "nmDLzy33_429"
   },
   "outputs": [],
   "source": [
    "selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
    "labels = labels[labels['breed'].isin(selected_breed_list)]\n",
    "labels['target'] = 1\n",
    "labels['rank'] = labels.groupby('breed').rank()['id']\n",
    "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
    "\n",
    "train = labels_pivot.sample(frac=0.8)\n",
    "valid = labels_pivot[~labels_pivot['id'].isin(train['id'])]\n",
    "print(train.shape, valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbjdVxCND9Cu"
   },
   "source": [
    "Custom dataset is going to be useful for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:21:25.372206Z",
     "iopub.status.busy": "2022-11-20T12:21:25.371623Z",
     "iopub.status.idle": "2022-11-20T12:21:25.385456Z",
     "shell.execute_reply": "2022-11-20T12:21:25.384555Z",
     "shell.execute_reply.started": "2022-11-20T12:21:25.372151Z"
    },
    "id": "YeBIQ3Y6_42-"
   },
   "outputs": [],
   "source": [
    "class DogsDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = '{}.jpg'.format(self.labels.iloc[idx, 0])\n",
    "        fullname = join(self.root_dir, img_name)\n",
    "        image = Image.open(fullname)\n",
    "        labels = self.labels.iloc[idx, 1:].to_numpy().astype('float')\n",
    "        labels = np.argmax(labels)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return [image, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:21:25.639926Z",
     "iopub.status.busy": "2022-11-20T12:21:25.639454Z",
     "iopub.status.idle": "2022-11-20T12:21:25.648535Z",
     "shell.execute_reply": "2022-11-20T12:21:25.647318Z",
     "shell.execute_reply.started": "2022-11-20T12:21:25.639888Z"
    },
    "id": "Pi1WBa83_42-"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "ds_trans = transforms.Compose([transforms.Resize(224),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.ToTensor(),\n",
    "                               normalize])\n",
    "train_ds = DogsDataset(train, data_dir + 'train/', transform=ds_trans)\n",
    "valid_ds = DogsDataset(valid, data_dir + 'train/', transform=ds_trans)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:21:25.847758Z",
     "iopub.status.busy": "2022-11-20T12:21:25.847349Z",
     "iopub.status.idle": "2022-11-20T12:21:25.854367Z",
     "shell.execute_reply": "2022-11-20T12:21:25.853367Z",
     "shell.execute_reply.started": "2022-11-20T12:21:25.847725Z"
    },
    "id": "rsZF3ehw_42-"
   },
   "outputs": [],
   "source": [
    "def imshow(axis, inp):\n",
    "    \"\"\"Denormalize and show\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    axis.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:21:27.116968Z",
     "iopub.status.busy": "2022-11-20T12:21:27.116556Z",
     "iopub.status.idle": "2022-11-20T12:21:48.607590Z",
     "shell.execute_reply": "2022-11-20T12:21:48.606428Z",
     "shell.execute_reply.started": "2022-11-20T12:21:27.116931Z"
    },
    "id": "YaOJt29S_42_"
   },
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dl))\n",
    "print(img.size(), label.size())\n",
    "fig = plt.figure(1, figsize=(16, 4))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(1, 4), axes_pad=0.05)    \n",
    "for i in range(img.size()[0]):\n",
    "    ax = grid[i]\n",
    "    imshow(ax, img[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyQlkHyl_42_"
   },
   "source": [
    "# Task 1: Transfer Learning (2 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icwJfGhzEWGV"
   },
   "source": [
    "Pick up some pretrained model, e.g. resnet 50 and tune it for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T12:22:42.969917Z",
     "iopub.status.busy": "2022-11-20T12:22:42.969487Z",
     "iopub.status.idle": "2022-11-20T12:23:03.494546Z",
     "shell.execute_reply": "2022-11-20T12:23:03.492219Z",
     "shell.execute_reply.started": "2022-11-20T12:22:42.969876Z"
    },
    "id": "D9giVv4z_42_"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "inputs, labels = next(iter(train_dl))\n",
    "resnet = resnet.to(device)\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "outputs = resnet(inputs)\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPkcuNZ7_42_"
   },
   "source": [
    "This models provides us with 1000 values, representing the classes which ResNet was trained on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m596WCT2_42_"
   },
   "source": [
    "Replace last layer with one that predicts the 64 classes. \n",
    "The network weights should be fixed expected for the last layer that is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7alchbxh_43A",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_model(dataloders,\n",
    "                model,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                num_epochs=1):\n",
    "    # Train the model and evaluate train and test accuracy\n",
    "    # YOUR CODE\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "vzD9iRef_43A",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "# freeze all model parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# add new layer\n",
    "# hint: you can get the number of features\n",
    "# using in_features, e.g resnet.fc.in_features\n",
    "\n",
    "# resnet.fc = ...\n",
    "\n",
    "# resnet = resnet.cuda()\n",
    "\n",
    "# criterion = ...\n",
    "# optimizer = ...\n",
    "# scheduler = ...\n",
    "\n",
    "dloaders = {'train':train_dl, 'valid':valid_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OV3Q2QDg_43A"
   },
   "outputs": [],
   "source": [
    "model = train_model(dloaders, resnet, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "FCEvPTyc_43A",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def visualize_model(dataloders, model, num_images=16):\n",
    "    cnt = 0\n",
    "    fig = plt.figure(1, figsize=(16, 16))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=(4, 4), axes_pad=0.05)\n",
    "    for i, (inputs, labels) in enumerate(dataloders['valid']):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            ax = grid[cnt]\n",
    "            imshow(ax, inputs.cpu().data[j])\n",
    "            ax.text(10, 210, ' Prediction: {}\\n Real Label: {}'.format(preds[j], labels.data[j]), \n",
    "                    color='k', backgroundcolor='w', alpha=0.8)\n",
    "            cnt += 1\n",
    "            if cnt == num_images:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlTfl4Hl_43B"
   },
   "outputs": [],
   "source": [
    "visualize_model(dloaders, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_I10c0tI19m"
   },
   "source": [
    "# Task 2: Low-dimensional dogs (4 points)\n",
    "Train a **Conditional CNN Autoencoder** that takes class labels into account. Show examples of interpolations between instances of different classes in a latent space and related representation of images in original space (just the same way we did it during practical session). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe8ibPgIG4YZ"
   },
   "source": [
    "# Task 3: Boosting the quality (2 points)\n",
    "\n",
    "The general objective here is to boost the quality you got on the first step. \n",
    "You can tune one/two more models from `torchvision` or `timm` and stack their predictions **OR** create your own CNN and use the encoder of your Autoencoder from 2nd task **OR** both. \n",
    "\n",
    "Don't forget to compare your models properly, e.g. it's not enough to run them for only a few epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Hx9w2a-Kpeb"
   },
   "source": [
    "Write a comment on model comparison, things and ideas that helped boost the quality, and anything else you would like to share. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
