{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2022/blob/master/01-intro/DataHandling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_nitmHugcSH"
   },
   "source": [
    "# Welcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfojW1Laghph"
   },
   "source": [
    "During the practical sessions of the course we are going to use [Python programming language](https://www.python.org) in the [Google Colab environment](https://colab.research.google.com). Alternatively you can download some other python distribution, e.g. [anaconda](https://www.anaconda.com/) and run jupyter locally (see the [docs](https://jupyter.readthedocs.io/en/latest/running.html) for more info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAa6UFGdwp2z"
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCkInromwobd"
   },
   "source": [
    "If you are new to Python, please consider reading through the following tutorial:\n",
    " - https://docs.python.org/3.7/tutorial/\n",
    "\n",
    "In particular, the following parts of it should provide a more or less comprehensive introduction to the must-know basics:\n",
    "   - https://docs.python.org/3.7/tutorial/introduction.html\n",
    "   - https://docs.python.org/3.7/tutorial/controlflow.html\n",
    "   - https://docs.python.org/3.7/tutorial/datastructures.html\n",
    "   - https://docs.python.org/3.7/tutorial/modules.html\n",
    "   - https://docs.python.org/3.7/tutorial/classes.html\n",
    "\n",
    "Don't forget to follow [PEP-8](https://peps.python.org/pep-0008/). You may also check other[style guides](https://google.github.io/styleguide/pyguide.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNKpO_suinc-"
   },
   "source": [
    "An overview of basic features of the Google Colab environment can be found [here](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw1cuRi7hhzz"
   },
   "source": [
    "# Tabular Playground Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3muhqoaJXVL"
   },
   "source": [
    "![Tabular Playground Series](https://storage.googleapis.com/kaggle-competitions/kaggle/33101/logos/header.png?t=2021-12-30-01-23-41)\n",
    "\n",
    "This notebook's gonna teach you to use the basic data science stack for python: jupyter, numpy, matplotlib and sklearn.\n",
    "\n",
    "We are going to use [Tabular Playground Series](https://www.kaggle.com/competitions?searchQuery=Tabular+Playground+Series) as the main data sourse for the experiments. \n",
    "\n",
    "\"These competitions are a great choice for people looking for something in between the Titanic Getting Started competition and the Featured competitions.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_J_iM9Hjwc3"
   },
   "source": [
    "## Part I: Jupyter notebooks recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyB4dc4Lt7xp"
   },
   "source": [
    "This whole document you are looking at right now is a **jupyter notebook**. You can think of jupyter as of a browser-friendly python development environment.\n",
    "\n",
    "For each notebook there's a python interpreter running behind the scenes, also called a **kernel**. The notebook consists of **cells** - either *code* cells, or *text* cells. E.g. this text you're reading is in a text cell.\n",
    "\n",
    "An example of a code cell can be found below. You can execute its code by placing the coursor in it and hitting `Shift + Enter`.\n",
    "\n",
    "__please keep running all the code cells as you read__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJak2EJ-vEYd"
   },
   "outputs": [],
   "source": [
    "print('Hellow world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMZCQoKzvMJv"
   },
   "source": [
    "Note that same python session is used to run the code from different cells. So, for example, by defining a variable in one cell, you can re-use it in another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeSmID9LvKgS"
   },
   "outputs": [],
   "source": [
    "some_number = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7o2AxcoveeN"
   },
   "outputs": [],
   "source": [
    "some_number**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9QW0Uojvlxh"
   },
   "source": [
    "Jupyter allows you to run cells in an arbitrary order, which may make your code a bit messy and complicated to debug. In general it's a good practice to write your code such that it successfully runs from top to bottom in a clean environment. To reset your environment back to a clean state click `Runtime -> Restart runtime` (in regular jupter: `Kernel -> Restart`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De2BsSxGJXVV"
   },
   "source": [
    "**The most important feature** of jupyter notebooks for this course: \n",
    "* contextual help: the behaviour depends on whether you're running this in google colab or in regular jupyter.\n",
    "* In colab the suggestions / documentation will appear automatically as you type.\n",
    "* In regular jupyter if you're typing something, press `Tab` to see automatic suggestions / `Shift + Tab` for function documentation.\n",
    "\n",
    "You can use [Markdown](https://jupyter.brynmawr.edu/services/public/dblank/Jupyter%20Notebook%20Users%20Manual.ipynb#4.-Using-Markdown-Cells-for-Writing) and [LaTeX](https://stackoverflow.com/questions/13208286/how-to-write-latex-in-ipython-notebook) through the cells as well.\n",
    "\n",
    "*Note: here we'll assume you're using google colab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oQdc9MIJXVW"
   },
   "outputs": [],
   "source": [
    "# run this first\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FZxJodmJXVZ"
   },
   "outputs": [],
   "source": [
    "# Place your cursor at the end of the unfinished line below and \n",
    "# type in '.' to see the contextual help and\n",
    "# find a function that computes arctangent from two parameters (should\n",
    "# have 2 in it's name).\n",
    "# Once you chose it, put an opening bracket character to\n",
    "# see the docs.\n",
    "\n",
    "math  # <--- type in a '.' symbol to see suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cY1PEyznRYw"
   },
   "source": [
    "## Part II: Numpy and vectorized computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4luG6vWXJXWU"
   },
   "source": [
    "Almost any machine learning model requires some computational heavy lifting usually involving linear algebra problems. Unfortunately, raw python is terrible at this because each operation is interpreted at runtime. \n",
    "\n",
    "So instead, we'll use `numpy` - a library that lets you run blazing fast computation with vectors, matrices and other tensors. It's written in lower-level programming languages like C or Fortran and only uses python as an interface.\n",
    "\n",
    "Quoting [documentation](https://numpy.org/devdocs/user/quickstart.html):\n",
    "> NumPy’s main object is the homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type, indexed by a tuple of non-negative integers. In NumPy dimensions are called axes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This object is called `numpy.ndarray` (\"nd\" standing for \"N-dimensional\"). It is also aliased to `numpy.array` and consists of two major components: the raw array data (from now on, referred to as the data buffer), and the information about the raw array data.\n",
    "\n",
    "The data buffer is typically what people think of as arrays in C or Fortran, a contiguous (and fixed) block of memory containing fixed-sized data items. NumPy also contains a significant set of data that describes how to interpret the data in the data buffer. This extra information contains (among other things):\n",
    "\n",
    "* The basic data element’s size in bytes.\n",
    "\n",
    "* The start of the data within the data buffer (an offset relative to the beginning of the data buffer).\n",
    "\n",
    "* The number of dimensions and the size of each dimension.\n",
    "\n",
    "* The separation between elements for each dimension (the stride). This does not have to be a multiple of the element size.\n",
    "\n",
    "* The byte order of the data (which may not be the native byte order).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcTokNL-JXWV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([5,4,3,2,1])\n",
    "print(\"a = \", a)\n",
    "print(\"b = \", b)\n",
    "\n",
    "# math and boolean operations can applied to each element of an array\n",
    "print(\"a + 1 =\", a + 1)\n",
    "print(\"a * 2 =\", a * 2)\n",
    "print(\"a == 2\", a == 2)\n",
    "# ... or corresponding elements of two (or more) arrays\n",
    "print(\"a + b =\", a + b)\n",
    "print(\"a * b =\", a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "479Etj_pG7WU"
   },
   "source": [
    "**All the solutions you share can give you additional points that can be added to HW's ones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40slF_H1JXWY"
   },
   "outputs": [],
   "source": [
    "# Your turn: compute half-products of a and b elements (halves of products)\n",
    "def half_product(a, b):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYvyRQAQL083"
   },
   "outputs": [],
   "source": [
    "half_product(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnNXgtaaJXWa"
   },
   "outputs": [],
   "source": [
    "# compute elementwise quotient between squared a and (b plus 1)\n",
    "def quotient(a,b):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twC3QxYAL9cV"
   },
   "outputs": [],
   "source": [
    "quotient(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSkrSyKTnJBp"
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHV6HlQgoL-r"
   },
   "source": [
    "There's a number of functions to create arrays of zeros, ones, ascending/descending numbers etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCqkfcCWoi1I"
   },
   "outputs": [],
   "source": [
    "np.zeros(shape=(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAee3VdtorX8"
   },
   "outputs": [],
   "source": [
    "np.ones(shape=(2, 5), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymW4lMqpozFn"
   },
   "outputs": [],
   "source": [
    "np.arange(3, 15, 2) # start, stop, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQi-FGqto_ty"
   },
   "outputs": [],
   "source": [
    "np.linspace(0, 10, 11) # divide [0, 10] interval into 11 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d7MlvuqpJ0S"
   },
   "outputs": [],
   "source": [
    "np.logspace(1, 10, 10, base=2, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4hb3shSpdBf"
   },
   "source": [
    "You can easily reshape arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83xNeecTphm4"
   },
   "outputs": [],
   "source": [
    "np.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XS-w_lLJd8uN"
   },
   "source": [
    "The `strides` of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4CRnMEPd5dI"
   },
   "outputs": [],
   "source": [
    "d = np.arange(12).reshape(2, -1)\n",
    "print(d)\n",
    "print(d.strides)\n",
    "print((d.shape[1] * d.dtype.itemsize, d.dtype.itemsize))\n",
    "d = d.reshape(-1, 2)\n",
    "print(d)\n",
    "d.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_evgKCtpzpk"
   },
   "source": [
    "or add dimensions of size 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "It_JTbIiqCTH"
   },
   "outputs": [],
   "source": [
    "print(np.arange(3)[:, np.newaxis])\n",
    "print('---')\n",
    "print(np.arange(3)[np.newaxis, :])\n",
    "\n",
    "#### Or similarly:\n",
    "\n",
    "# print(np.arange(3)[:, None])\n",
    "# print('---')\n",
    "# print(np.arange(3)[None, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eE5Uq8GqO75"
   },
   "source": [
    "Such dimensions are automatically [broadcast](https://numpy.org/doc/stable/user/basics.broadcasting.html) when doing mathematical operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmO2UtjtqcEU"
   },
   "outputs": [],
   "source": [
    "print(np.arange(3)[:, np.newaxis] + np.zeros(shape=(3, 3), dtype=int))\n",
    "print()\n",
    "print(np.arange(3)[np.newaxis, :] + np.zeros(shape=(3, 3), dtype=int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CX6xP8UgX10b"
   },
   "source": [
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when:\n",
    "\n",
    "*   they are equal, or\n",
    "*   one of them is 1\n",
    "\n",
    "If these conditions are not met, a `ValueError`: operands could not be broadcast together exception is thrown, indicating that the arrays have incompatible shapes. The size of the resulting array is the size that is not 1 along each axis of the inputs.\n",
    "\n",
    "When either of the dimensions compared is one, the other is used. In other words, dimensions with size 1 are stretched or “copied” to match the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEE0W788XDRZ"
   },
   "source": [
    "![broadcasting_2[1].png](https://numpy.org/doc/stable/_images/broadcasting_2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfmFlVopqzId"
   },
   "source": [
    "There is also a number of ways to stack arrays together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzfKzymGq3wX"
   },
   "outputs": [],
   "source": [
    "matrix1 = np.arange(50).reshape(10, 5)\n",
    "matrix2 = -np.arange(20).reshape(10, 2)\n",
    "\n",
    "np.concatenate([matrix1, matrix2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqJnzNehrYYP"
   },
   "outputs": [],
   "source": [
    "A = matrix1[:,0]\n",
    "B = matrix2[:,0]\n",
    "\n",
    "print(A)\n",
    "print('---')\n",
    "print(B)\n",
    "print('---')\n",
    "print(np.stack([A, B], axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MulZJhPBr6ie"
   },
   "source": [
    "Any matrix can be transposed easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIeOCQ-wr_Q6"
   },
   "outputs": [],
   "source": [
    "print(matrix2)\n",
    "print('---')\n",
    "print(matrix2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEP-dcq-fk5c"
   },
   "source": [
    "You don't create a copy of your data, but you change the `strides`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIceEFFiMK5k"
   },
   "outputs": [],
   "source": [
    "print('matrix2.shape =', matrix2.shape, ' strides =', matrix2.strides)\n",
    "print('matrix2.T.shape =', matrix2.T.shape, ' strides =', matrix2.T.strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnajGvSrsP-t"
   },
   "outputs": [],
   "source": [
    "# Your turn: make a (7 x 5) matrix with e_ij = i\n",
    "# (i - row number, j - column number)\n",
    "#\n",
    "# Avoid using loops.\n",
    "\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56X724n8nNK9"
   },
   "source": [
    "### How fast is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7ugCw1wJXWc"
   },
   "source": [
    "Let's compare computation time for python and numpy\n",
    "* Two arrays of 10^6 elements\n",
    " * first - from 0 to 1 000 000\n",
    " * second - from 99 to 1 000 099\n",
    " \n",
    "* Computing:\n",
    " * elemwise sum\n",
    " * elemwise product\n",
    " * square root of first array\n",
    " * sum of all elements in the first array\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkaH4AkUJXWd"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# ^-- this \"magic\" measures and prints cell computation time\n",
    "\n",
    "# Option I: pure python\n",
    "arr_1 = range(1000000)\n",
    "arr_2 = range(99,1000099)\n",
    "\n",
    "\n",
    "a_sum = []\n",
    "a_prod = []\n",
    "sqrt_a1 = []\n",
    "for i in range(len(arr_1)):\n",
    "    a_sum.append(arr_1[i]+arr_2[i])\n",
    "    a_prod.append(arr_1[i]*arr_2[i])\n",
    "    a_sum.append(arr_1[i]**0.5)\n",
    "    \n",
    "arr_1_sum = sum(arr_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BasUnM6uJXWf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Option II: start from python, convert to numpy\n",
    "arr_1 = range(1000000)\n",
    "arr_2 = range(99,1000099)\n",
    "\n",
    "arr_1, arr_2 = np.array(arr_1) , np.array(arr_2)\n",
    "\n",
    "\n",
    "a_sum = arr_1 + arr_2\n",
    "a_prod = arr_1 * arr_2\n",
    "sqrt_a1 = arr_1 ** .5\n",
    "arr_1_sum = arr_1.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whU6BvJ6JXWi"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Option III: pure numpy\n",
    "arr_1 = np.arange(1000000)\n",
    "arr_2 = np.arange(99,1000099)\n",
    "\n",
    "a_sum = arr_1 + arr_2\n",
    "a_prod = arr_1 * arr_2\n",
    "sqrt_a1 = arr_1 ** .5\n",
    "arr_1_sum = arr_1.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Jc5_Z5wJXWl"
   },
   "source": [
    "If you want more serious benchmarks, take a look at [this](http://brilliantlywrong.blogspot.ru/2015/01/benchmarks-of-speed-numpy-vs-all.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2cYqf_UJXWm"
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPtaPKy3uI6A"
   },
   "source": [
    "### Other numpy functions and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-8KaYRmuM4m"
   },
   "source": [
    "There's also a bunch of pre-implemented operations including logarithms, trigonometry, vector/matrix products and aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RklGSklbJXWn"
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([5,4,3,2,1])\n",
    "print(\"numpy.sum(a) = \", np.sum(a))\n",
    "print(\"numpy.mean(a) = \", np.mean(a))\n",
    "print(\"numpy.min(a) = \",  np.min(a))\n",
    "print(\"numpy.argmin(b) = \", np.argmin(b))  # index of minimal element\n",
    "print(\"numpy.dot(a,b) = \", np.dot(a, b))      # dot product. Also used for matrix/tensor multiplication\n",
    "print(\"numpy.unique(['male','male','female','female','male']) = \", np.unique(['male','male','female','female','male']))\n",
    "\n",
    "# and tons of other stuff. see http://bit.ly/2u5q430 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4N_kpGw3NcGk"
   },
   "outputs": [],
   "source": [
    "# most of this functions are also implemented as members of numpy arrays, e.g.:\n",
    "print('a.min() =', a.min())\n",
    "print('a.mean() =', a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jkq07GT5JXW0"
   },
   "outputs": [],
   "source": [
    "print(\"Boolean operations\")\n",
    "\n",
    "print('a = ', a)\n",
    "print('b = ', b)\n",
    "print(\"a > 2\", a > 2)\n",
    "print(\"numpy.logical_not(a>2) = \", np.logical_not(a>2))\n",
    "print(\"numpy.logical_and(a>2,b>2) = \", np.logical_and(a > 2,b > 2))\n",
    "print(\"numpy.logical_or(a>2,b<3) = \", np.logical_or(a > 2, b < 3))\n",
    "\n",
    "print(\"\\n shortcuts\")\n",
    "print(\"~(a > 2) = \", ~(a > 2))                    #logical_not(a > 2)\n",
    "print(\"(a > 2) & (b > 2) = \", (a > 2) & (b > 2))  #logical_and\n",
    "print(\"(a > 2) | (b < 3) = \", (a > 2) | (b < 3))  #logical_or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBkDTTOLJXW3"
   },
   "source": [
    "Another numpy feature we'll need is indexing: selecting elements from an array. \n",
    "Aside from python indexes and slices (e.g. a[1:4]), numpy also allows you to select several elements at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDtdSCMAPyLL"
   },
   "outputs": [],
   "source": [
    "a = np.arange(24).reshape(4, 6)\n",
    "print(a)\n",
    "print('---')\n",
    "print(a[1:3,0:6:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhXHB6fgJXW4"
   },
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 4, 9, 16, 25])\n",
    "ix = np.array([1,2,5])\n",
    "print(\"a = \", a)\n",
    "print(\"Select by element index\")\n",
    "print(\"a[[1,2,5]] = \", a[ix])\n",
    "\n",
    "print(\"\\nSelect by boolean mask\")\n",
    "print(\"a[a > 5] = \", a[a > 5])     # select all elements in a that are greater than 5\n",
    "print(\"(a % 2 == 0) =\", a % 2 == 0) # True for even, False for odd\n",
    "print(\"a[a % 2 == 0] =\", a[a % 2 == 0]) # select all elements in a that are even"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD6NjAugj_3y"
   },
   "source": [
    "## Part III: Loading data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0OYaO-6JXVb"
   },
   "source": [
    "Pandas is a library that helps you load the data, prepare it and perform some lightweight analysis. The god object here is the `pandas.DataFrame` - a 2d table with batteries included (it actually runs numpy under the hood).\n",
    "\n",
    "Let's donwload the data and perform a small **E**xploratory **D**ata **A**nalysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLZSNMxNFR-W"
   },
   "source": [
    "The most convinient and proper way to do it that allows you to avoid using your local storage looks as follows:\n",
    "\n",
    "1. Go to your Kaggle account, Scroll to API section and Click on Create New API Token - It will download kaggle.json file on your **local** machine.\n",
    "\n",
    "2. Upload it to the Google Colab env.\n",
    "\n",
    "3. Move it using comands bellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "dBaZHbB1Dt5Z"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLUjnvLAuCYU"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets list -s tabular-playground-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T18TbqfPFXUL"
   },
   "source": [
    "Download the data using the name of the competition you want to work with. Don't forget to accept the rules of the competition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX-OE6_kDPuO"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c 'tabular-playground-series-aug-2022'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiDXtzg7F7UT"
   },
   "source": [
    "In case you don't have Kaggle account or you just want to avoid the steps mentioned above, you can just download it from the course repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyJE7OdxESxz"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2022/main/01-intro/tabular-playground-series-aug-2022.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMiK_rJcEFLl"
   },
   "outputs": [],
   "source": [
    "!unzip /content/tabular-playground-series-aug-2022.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOte8Vs8Gp4C"
   },
   "source": [
    "Now let's use Pandas to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G36oVo3RJXVc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/content/data/train.csv',\n",
    "                    index_col='id') # this yields a pandas.DataFrame\n",
    "data.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEvLO4nvJXVf"
   },
   "outputs": [],
   "source": [
    "# Take a look at the data\n",
    "\n",
    "data.head() # selects top 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXpNDAgk3N6W"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zpm0KYxF3jGs"
   },
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDHw3sHgJXVj"
   },
   "source": [
    "#### About the data\n",
    "This data represents the results of a large product testing study. For each `product_code` you are given a number of product `attributes` (fixed for the code) as well as a number of `measurement` values for each individual product, representing various lab testing methods. Each product is used in a simulated real-world environment experiment, and and absorbs a certain amount of fluid (`loading`) to see whether or not it fails.\n",
    "\n",
    "Your task is to use the data to predict individual product failures of new codes with their individual lab test results. The training data includes the target `failure` and you need to predict the likelihood each test id will experience a failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWmRBFP6JXVl"
   },
   "outputs": [],
   "source": [
    "# table dimensions\n",
    "print(\"len(data) = \", len(data))\n",
    "print(\"data.shape = \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dt6itIHBJXVn"
   },
   "outputs": [],
   "source": [
    "# select a single row\n",
    "print(data.loc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdpiKMr7JXVq"
   },
   "outputs": [],
   "source": [
    "# select a single column.\n",
    "loadings = data[\"loading\"] # alternatively: data.loading\n",
    "print(loadings.loc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ao3OhDtJXVu"
   },
   "outputs": [],
   "source": [
    "# select several columns and rows at once\n",
    "data.loc[5:10, (\"loading\", \"failure\")]    # alternatively: data[[\"loading\",\"failure\"]].loc[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7jqzyjLp9qe"
   },
   "source": [
    "### `loc` vs `iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR-MSiiiqDB4"
   },
   "source": [
    "There are two ways of indexing the rows in pandas:\n",
    " *   by index column values (`id` in our case) – use `data.loc` for that\n",
    " *   by positional index - use `data.iloc` for that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXCOFn0Fqr1M"
   },
   "source": [
    "Note that index column starts from 1, so positional index 0 will correspond to index column value 1, positional 1 to index column value 2, and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWD9vfcIqjAH"
   },
   "outputs": [],
   "source": [
    "print(data.index)\n",
    "print('------')\n",
    "print(\"data.iloc[0]:\")\n",
    "print(data.iloc[0])\n",
    "print('------')\n",
    "print(\"data.loc[1]:\")\n",
    "print(data.loc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqkU4nzfgxok"
   },
   "source": [
    "Also note that when indexing with `.loc` both slice ends are included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lI0C2cG8g3To"
   },
   "outputs": [],
   "source": [
    "data.loc[2:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMf9SqMwg7Uw"
   },
   "source": [
    "while with `.iloc` the end is excluded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5JFLNVag6aP"
   },
   "outputs": [],
   "source": [
    "data.iloc[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJgo08cJi6i6"
   },
   "source": [
    "More complicated indexing (similar to boolean indexing in numpy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMkc1lqHPjAo"
   },
   "outputs": [],
   "source": [
    "data.loc[(data['loading'] < 90) & (data['product_code'] == np.random.choice(data.product_code.unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyQmIF5Rdngw"
   },
   "outputs": [],
   "source": [
    "data.query('2.1 * measurement_9 < measurement_10 and loading < 111')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln3hUck0JXVx"
   },
   "source": [
    "### Your turn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0surSILJXVy"
   },
   "outputs": [],
   "source": [
    "# select studies number 13 and 666 in a single line - did they fail?\n",
    "\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfL_YYOVJXV3"
   },
   "outputs": [],
   "source": [
    "# compute the overall fail-rate (what fraction of studies failed)\n",
    "# do we face a balanced train dataset?\n",
    "\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaDF00ADJXV7"
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZAezJgDJXV8"
   },
   "source": [
    "Pandas also has some basic data analysis tools. For one, you can quickly display statistical aggregates for each column using `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHtn-GlbJXV8"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hp-OG6bOJXWA"
   },
   "source": [
    "Some columns contain __NaN__ values - this means that there is no data there. For example, study `#26565` has unknown `measurement_16`. To simplify the future data analysis, we'll replace NaN values by using pandas `fillna` function.\n",
    "\n",
    "_Note: we do this so easily because it's a tutorial. In general, you think twice before you modify data like this._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHEegWTOJXWK"
   },
   "outputs": [],
   "source": [
    "data['measurement_9'] = data['measurement_9'].fillna(value=data['measurement_9'].mean())\n",
    "data['measurement_16'].fillna(value=data['measurement_16'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSIS7m9RJXWO"
   },
   "outputs": [],
   "source": [
    "data.iloc[26565]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_oQnE9JhlWW"
   },
   "source": [
    "### Pandas + numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk8fA8HBJXWs"
   },
   "source": [
    "The important part: as pandas uses numpy under the hood, most of numpy functionality works with dataframes, as you can get their numpy representation with `.values` (most numpy functions will even work on pure pandas objects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE53osRgJXWs"
   },
   "outputs": [],
   "source": [
    "# calling np.max on a pure pandas column:\n",
    "column_name = 'measurement_17'\n",
    "print(\"Max {}: \".format(column_name), np.max(data[column_name]))\n",
    "\n",
    "# calling np.argmax on a numpy representation of a pandas column\n",
    "# to get its positional index:\n",
    "print(\"\\nThe study with the max \" + column_name + \":\\n\",\n",
    "      data.iloc[\n",
    "          np.argmax(data[column_name].values)\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5l90RFPN6SL"
   },
   "outputs": [],
   "source": [
    "# numpy works only with positional index:\n",
    "column_name = 'measurement_16'\n",
    "print(data[column_name].values.argmax())\n",
    "#     ^^^^^^^^^^^^^^^^^^^\n",
    "#     this part returns a numpy array, argmax of which we are calculating\n",
    "\n",
    "\n",
    "# in pandas you can ask for the index (i.e. value of the index column)\n",
    "# of the maximal element like this:\n",
    "print(data[column_name].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_xqJK6UJXW6"
   },
   "source": [
    "### Your turn\n",
    "\n",
    "Use numpy and pandas to answer a few questions about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7O68NpyJXWw"
   },
   "outputs": [],
   "source": [
    "# your code: compute mean loading and find max one.\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyDEaifrJXW8"
   },
   "outputs": [],
   "source": [
    "# which product code is more likely to fail?\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASsnUCRMJXWS"
   },
   "source": [
    "More pandas: \n",
    "* Official [tutorials](https://pandas.pydata.org/pandas-docs/stable/tutorials.html), including this [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html#min)\n",
    "* Bunch of cheat sheets awaits just one google query away from you (e.g. [basics](http://datacamp-community-prod.s3.amazonaws.com/dbed353d-2757-4617-8206-8767ab379ab3), [combining datasets](https://pbs.twimg.com/media/C65MaMpVwAA3v0A.jpg) and so on). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt0lgtQox2e1"
   },
   "source": [
    "## Part IV: plots and matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Odx24QWTJXW-"
   },
   "source": [
    "Using python to visualize the data is covered by yet another library: `matplotlib`.\n",
    "\n",
    "Just like python itself, matplotlib has an awesome tendency of keeping simple things simple while still allowing you to write complicated stuff with convenience (e.g. super-detailed plots or custom animations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QxD0DoLJXW-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "# ^-- this \"magic\" selects specific matplotlib backend suitable for\n",
    "# jupyter notebooks. For more info see:\n",
    "# https://ipython.readthedocs.io/en/stable/interactive/plotting.html#id1\n",
    "# (actually it's the default in google colab)\n",
    "\n",
    "#scatter-plot\n",
    "x = np.arange(5)\n",
    "print(\"x =\", x)\n",
    "print(\"x**2 =\", x**2)\n",
    "print(\"plotting x**2 vs x:\")\n",
    "plt.scatter(x, x**2)\n",
    "plt.show()  # show the first plot to begin drawing the next one\n",
    "\n",
    "plt.plot(x, x**2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fz5WDA4YJXXI"
   },
   "outputs": [],
   "source": [
    "# histogram - showing data density\n",
    "float_cols = [c for c in data.columns if data[c].dtype == float]\n",
    "\n",
    "_, axs = plt.subplots(2, 4, figsize=(10,5))\n",
    "\n",
    "for f, ax in zip(float_cols[:8], axs.ravel()):\n",
    "    bins = np.linspace(min(data[f]), max(data[f]), 50)\n",
    "    ax.hist(data[f], bins=bins, density=True)\n",
    "    ax.set_xlabel(f)\n",
    "\n",
    "plt.tight_layout(w_pad=1)\n",
    "plt.suptitle('Distributions of the continuous features', fontsize=15, y=1.12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4F8dkG_l7sw"
   },
   "outputs": [],
   "source": [
    "# or you can use inbuilt methods and combine it with pyplot\n",
    "data.failure.hist()\n",
    "plt.title('Failure hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdX4D1Pz2UV3"
   },
   "outputs": [],
   "source": [
    "# .plot() method allows you to plot in different styles\n",
    "data.product_code.value_counts().plot(kind='pie', autopct=\"%1.1f%%\",shadow=True, \n",
    "        startangle=45, explode=[0.065] * data.product_code.nunique());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqBRikzYqPgW"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpSzeTVCq13z"
   },
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 2, figsize=(19, 19))\n",
    "for product, ax in zip(np.unique(data.product_code)[:4], axs.ravel()):\n",
    "    corr = data[float_cols + ['measurement_0', 'measurement_1', 'measurement_2']][data.product_code == product].corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    sns.heatmap(corr, mask=mask, fmt='0.2f', \n",
    "                annot=True, cmap='Purples',  ax=ax, cbar=False)\n",
    "    ax.set_title(product)\n",
    "plt.tight_layout(w_pad=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmapamrGJXXM"
   },
   "outputs": [],
   "source": [
    "# plot a barplot of number of missing values in columns\n",
    "<YOUR CODE>\n",
    "\n",
    "# hint: use data.isnull() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHDcDWFKJXXS"
   },
   "source": [
    "* Extended [tutorial](https://matplotlib.org/2.0.2/users/pyplot_tutorial.html)\n",
    "* Other libraries for more sophisticated stuff: [Plotly](https://plot.ly/python/), and [Bokeh](https://bokeh.pydata.org/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARBewmPBye4-"
   },
   "source": [
    "## Part V (final): machine learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpc3yTBjJXXT"
   },
   "source": [
    "<img src='https://i.redd.it/k13eojlo31i31.png' width=500px>\n",
    "\n",
    "Scikit-learn is the tool for simple machine learning pipelines. \n",
    "\n",
    "It's a single library that unites a whole bunch of models under the common interface:\n",
    "* Create:__ `model = sklearn.whatever.ModelNameHere(parameters_if_any)`__\n",
    "* Train:__ `model.fit(X,y)`__\n",
    "* Predict:__ `model.predict(X_test)`__\n",
    "\n",
    "It also contains utilities for feature extraction, quality estimation or cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhbbBk93JXXV"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x = data[float_cols].copy()\n",
    "y = data[\"failure\"]\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# split the data into train(90%) and test(10%)\n",
    "train_ids = ...\n",
    "test_ids = ...\n",
    "\n",
    "# fit the model\n",
    "model.fit(...,... )\n",
    "\n",
    "# make the prediction\n",
    "test_predictions = model.predict(...)\n",
    "print(\"Test accuracy:\", accuracy_score(..., test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wxe6EeCSJXXY"
   },
   "source": [
    "Try to tune n_neighbors and add play around features to boost accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcdyuBflJXXZ"
   },
   "source": [
    "* Sklearn [tutorials](http://scikit-learn.org/stable/tutorial/index.html)\n",
    "* Sklearn [examples](http://scikit-learn.org/stable/auto_examples/index.html)\n",
    "* Sklearn [cheat sheet](http://scikit-learn.org/stable/_static/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toDL-cAILb8H"
   },
   "source": [
    "```\n",
    "```\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gdvIZBILdoo"
   },
   "source": [
    "## Bonus part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4z88BXYDLunO"
   },
   "source": [
    "### Pandas: adding new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8kPXF_mZLwO"
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2022/main/01-intro/train.csv #use Titanic Data for examples below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAqszFVKMHCG"
   },
   "source": [
    "To define a new column in a dataframe simply assign to it (if such a column exists it will get overwritten):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTf14P-ELzXD"
   },
   "outputs": [],
   "source": [
    "data['CabinUnknown'] = data.Cabin.isna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLtCIDVCMx3t"
   },
   "source": [
    "Be sure to use the approach with a `['ColumnName']` , rather than `.ColumnName`, otherwize it won't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctpV_MWvMh6b"
   },
   "outputs": [],
   "source": [
    "data.this_will_not_work = data.Age**2\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErWMVXfvcgrZ"
   },
   "source": [
    "### Pandas: one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBfOdHGGdCMC"
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(data.Embarked, prefix='Embarked').head()\n",
    "# added .head() for a more compact output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxqeVSdKd0DT"
   },
   "source": [
    "### Pandas: merging tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AP9PrE8qdyI_"
   },
   "outputs": [],
   "source": [
    "data_extended = pd.concat([\n",
    "                      data,\n",
    "                      pd.get_dummies(data.Embarked, prefix='Embarked')\n",
    "                    ], axis=1)\n",
    "data_extended.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeaeflaAeQ7W"
   },
   "source": [
    "### Pandas: groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP6HFtuRhwPD"
   },
   "source": [
    "This function provides a neat way to calculate some statistics for groups of entries with some common feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4QeQUKmiDSZ"
   },
   "outputs": [],
   "source": [
    "g = data.groupby('Embarked')\n",
    "# Now `g` is an iterable of dataframes split based on the values\n",
    "# in the 'Embarked' column:\n",
    "\n",
    "for embarked, group in g:\n",
    "  print(embarked, type(group), group.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZlGdJ3-jo05"
   },
   "outputs": [],
   "source": [
    "# You can calculate things on the groups simultaniously:\n",
    "\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-3FFL-hj8qP"
   },
   "outputs": [],
   "source": [
    "g.count() # this calculates the number of valid entries (excluding nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4KA9HsekPiA"
   },
   "outputs": [],
   "source": [
    "# You can also access individual columns:\n",
    "g.Fare.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRhTgAVHekYH"
   },
   "source": [
    "### Pandas: cut and qcut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c42YbZKlksNz"
   },
   "source": [
    "These functions let us split data into bins: `cut` makes linear splits, while `qcut` makes quantile-based splits. They both return a column of bins to which current entry belongs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHMNswNblHeB"
   },
   "outputs": [],
   "source": [
    "pd.cut(data.Age, 3).head() # '.head()' added for a more compact output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJGJhcqUlgKC"
   },
   "outputs": [],
   "source": [
    "pd.qcut(data.Age, 3).head() # '.head()' added for a more compact output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGLUZ8CmjD0"
   },
   "source": [
    "### Your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6ryMww4mlK-"
   },
   "source": [
    "Use `cut` and `groupby` to calculate survival rate for 3 age categories.\n",
    "\n",
    "**Hint:** you need to add the result of `cut` as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VD_cgA8m6WT"
   },
   "outputs": [],
   "source": [
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYc963-eepev"
   },
   "source": [
    "### Pandas: combining the tricks (survival vs ticket fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aA6C8vbLdJk"
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "data['qFare'] = pd.qcut(data.Fare, 20)\n",
    "\n",
    "sur_vs_price = data.groupby('qFare').Survived.mean()\n",
    "sur_vs_price_e = data.groupby('qFare').Survived.std() \\\n",
    "                        / data.groupby('qFare').Survived.count()**0.5\n",
    "\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "plt.errorbar(x=sur_vs_price.index.categories.mid,\n",
    "             y=sur_vs_price.values,\n",
    "             yerr=sur_vs_price_e.values,\n",
    "             xerr=(\n",
    "                 sur_vs_price.index.categories.right - \n",
    "                 sur_vs_price.index.categories.left\n",
    "               ) / 2,\n",
    "             fmt='o')\n",
    "plt.gca().set_xscale('log')\n",
    "plt.gca().xaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.gca().set_xticks(\n",
    "              list(range(3, 10)) +\n",
    "              list(range(10, 100, 10)) +\n",
    "              list(range(100, 700, 100))\n",
    "            )\n",
    "\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Survival probability');"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
