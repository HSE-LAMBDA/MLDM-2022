{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2022/blob/master/06-model-evaluation/QualityMetrics_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij_zY4soDF2Z"
   },
   "source": [
    "# Cross-validation riddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUCsY5OlDJPl"
   },
   "source": [
    "Here's a small example of cross-validation done wrongly. Can you spot the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSUzkXsC-R4H"
   },
   "outputs": [],
   "source": [
    "# Some imports...\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyDp3Xc_DaDM"
   },
   "source": [
    "**Plan:**\n",
    "\n",
    "- Let's create a binary classification dataset where targets are completely independent from the features\n",
    "  - *(i.e. no model could ever predict them well)*\n",
    "- We'll do some simple feature selection\n",
    "- And cross-validate a model on this data\n",
    "\n",
    "**Q:** what accuracy do we expect (classes are even)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHx51DKP8Rcf"
   },
   "source": [
    "We'll start from writing a class to select the best features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRNmKZJJ8W7x"
   },
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "  def __init__(self, num_features):\n",
    "    self.n = num_features # number of best features to select\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    # Select features that describe the targets best, i.e. have\n",
    "    # highest correlation with them:\n",
    "    covariance = ((X - X.mean(axis=0)) * (y[:,np.newaxis] - y.mean())).mean(axis=0)\n",
    "    self.best_feature_ids = np.argsort(np.abs(covariance))[-self.n:]\n",
    "\n",
    "  def transform(self, X):\n",
    "    return X[:,self.best_feature_ids]\n",
    "\n",
    "  def fit_transform(self, X, y):\n",
    "    self.fit(X, y)\n",
    "    return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6mu9gHgNBk_V",
    "outputId": "b2ca1fe5-90ae-4792-d193-9dc51f460382"
   },
   "outputs": [],
   "source": [
    "num_features_total = 1000\n",
    "num_features_best = 100\n",
    "\n",
    "N = 100\n",
    "\n",
    "# Dataset generation\n",
    "X = np.random.normal(size=(N, num_features_total))\n",
    "y = np.random.randint(2, size=N)\n",
    "\n",
    "# Feature selection:\n",
    "X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
    "\n",
    "# Simple classification model\n",
    "model = LinearSVC()\n",
    "\n",
    "# Estimatin accuracy using cross-validation:\n",
    "cv_score = cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
    "print(f\"CV score is {cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afadN3ZVFKjF"
   },
   "source": [
    "What's going on?! Why accuracy is so high?\n",
    "\n",
    "Maybe it just happened by chance? Let's repeat this experiment many times and histogram the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "QDbOMXnuC6uw",
    "outputId": "0722aeed-f580-406b-d93b-729581edb8ec"
   },
   "outputs": [],
   "source": [
    "num_features_total = 1000\n",
    "num_features_best = 100\n",
    "\n",
    "N = 100\n",
    "def experiment():\n",
    "  # Dataset generation\n",
    "  X = np.random.normal(size=(N, num_features_total))\n",
    "  y = np.random.randint(2, size=N)\n",
    "\n",
    "  # Feature selection:\n",
    "  X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
    "\n",
    "  # Simple classification model\n",
    "  model = LinearSVC()\n",
    "\n",
    "  # Estimatin accuracy using cross-validation:\n",
    "  return cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
    "\n",
    "results = [experiment() for _ in range(100)]\n",
    "plt.hist(results, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMYRjjqOLB5Z"
   },
   "source": [
    "## Task 1 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bLaEypoF5pb"
   },
   "source": [
    "Explain why the estimated model accuracy is not 50% on a dataset where targets were generated **independently from the features (!!!)**.\n",
    "\n",
    "Find and fix the problem (don't change the dataset generation or its parameters - `num_features_total`, `num_features_best`, `N`).\n",
    "\n",
    "*Hint: the problem is in the overall logic, and not a bug in the code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfT36WPTLyqB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's come back to Task 3 of Data Handling HW.\n",
    "Build a model with KNeighborsClassifier to get a higher accuracy on 5-fold Cross Validation than you achieve using your previosly fitted model (you can just copy the params from the previous notebook). \n",
    "\n",
    "Use `sklearn.model_selection.GridSearchCV` to find best parameters.  You may check the parameters'  description as follows:\n",
    "``` python\n",
    "help(KNeighborsClassifier)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2022/main/01-intro/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "data = pd.read_csv(\"train.csv\", index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "QualityMetrics_HW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
